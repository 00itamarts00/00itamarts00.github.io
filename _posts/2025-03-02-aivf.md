---
layout: post
title: AI-Powered Embryo Selection: Advancing IVF with Deep Learning
subtitle: AiVF
cover-img: assets/img/aivf_cover_img.jpg
tags: [AI in Healthcare, MultiGPU Training, Embryo Viability, Medical AI, Reproductive Medicine, AI for IVF, FertilityTech, Clinical AI, AI in Medicine, Healthcare Innovation]
comments: true
mathjax: true
author: Itamar Tsayag
---

## Introduction  

During my time as a **Lead Computer Vision Algorithm Developer at AiVF (2023-2024)**, I developed AiVF's **flagship deep learning models**, which formed the foundation of the company's technology. AiVF leverages AI to estimate **embryo viability** and improve **IVF success rates** by analyzing **time-lapse videos of embryos** from **insemination (zygote stage) to day 5 (blastocyst stage)**.  

I developed three core deep learning models:  

- **3-Day Embryo Viability Prediction Model**  
- **5-Day Embryo Viability Prediction Model**  
- **Non-Invasive Preimplantation Genetic Testing (PGT) Model**  

These models predict:  
1. **Embryo viability at days 3 and 5**  
2. **The likelihood of an embryo having a negative preliminary genetic test result (PGT)**  

A visual example of **embryo development over time** is shown in this **time-lapse video**:  

<iframe width="100%" height="400" src="https://www.youtube.com/embed/6KWVP-zDIAg" frameborder="0" allowfullscreen></iframe>  

---

## Data, Model Architecture & Training  

To build a robust AI model, we gathered a **large dataset** of **time-lapse embryo videos** captured during incubation. Since storing full-length videos is computationally expensive, I implemented a **preprocessing pipeline** to select **key frames** that carried the most biologically relevant information.  

<!-- (https://arxiv.org/abs/2106.13230) -->
For training, I used the **[Video SWIN Transformer]**â€”a transformer-based architecture capable of learning both **spatial and temporal features**. It provided:  

- **Self-attention mechanisms** to capture key developmental markers  
- **Better generalization** across diverse datasets  
- **Improved efficiency over standard CNN-based models**  

Since each **video contained multiple images**, memory usage was a key challenge. To handle this, I implemented the models using **PyTorch with Lightning**, which allowed for **multi-GPU training**. Lightning enabled:  

- **Scalability** for handling large video datasets  
- **Seamless distributed training**  
- **Optimized memory management** via automatic gradient accumulation  

## Evaluation & Real-World Impact  

To assess accuracy, we tested the model using **categorical cross-entropy** on real-world **fetal heartbeat data** from **weeks 5 to 7** of pregnancy. However, beyond standard validation, the **true business success** of the model was measured by its impact on **IVF efficiency**.  

A key metric for clinics is **"transfers per pregnancy"**, representing how many embryo transfers are needed before achieving a successful pregnancy. Before using AiVF's AI models, clinics averaged **~1.6 transfers per pregnancy**. After integrating our AI-based selection, this number **decreased substantially** (exact figures are confidential), directly improving:  

- **Higher success rates per transfer**  
- **Lower financial & emotional burden for patients**  
- **Increased efficiency in fertility clinics**

---

## Conclusion  

Developing AiVFâ€™s deep learning models was a **challenging but rewarding** experience. Our AI didnâ€™t just improve **predictive accuracy**â€”it had a **measurable real-world impact** by reducing the number of transfers needed per pregnancy and improving overall IVF outcomes.  

From a technical perspective, **leveraging PyTorch Lightning** for **multi-GPU training** was a game-changer, enabling **efficient video-based model training** at scale.  

As AI continues to evolve in reproductive medicine, I believe deep learning-driven embryo assessment will become an **industry standard**, helping more families achieve successful pregnancies. ðŸš€  

---
